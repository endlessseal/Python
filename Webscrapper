import re
import threading
import os
import requests
import urllib3
import urllib.request
import time
from bs4 import BeautifulSoup

def fixingText(string):
    return string.encode('utf8').decode('unicode_escape').encode('latin1').decode('Utf-8')

def getPower(fileName):
    with open(fileName, mode='r',encoding='utf-8') as f:
        for line in f:
            if 'Power' in line:
                return line
def getSoul(fileName):
    with open(fileName, mode='r', encoding='utf-8') as f:
        for line in f:
            if 'Soul:' in line:
                return line

def getTrait(fileName):
    with open(fileName, mode='r', encoding='utf-8') as f:
        for line in f:
            if 'Traits:' in line:
                return line

def getTrigger(fileName):
    with open(fileName, mode='r', encoding='utf-8') as f:
        for line in f:
            if 'Trigger:' in line:
                return line

def getCost(fileName):
    with open(fileName, mode='r', encoding='utf-8') as f:
        for line in f:
            if 'Cost:' in line:
                return line

def getColor(fileName):
    with open(fileName, mode='r', encoding='utf-8') as f:
        for line in f:
            if 'Color:' in line:
                return line

def getLevel(fileName):
    with open(fileName, mode='r', encoding='utf-8') as f:
        for line in f:
            if 'Level:' in line:
                return line

def getType(fileName):
    searchWords = ('Type: Character', 'Type: Event', 'Type: Climax', 'Type: Unknown')
    with open(fileName, mode='r', encoding='utf-8') as f:
        for line in f:
            if any(x in line for x in searchWords):
                return line

def getCode(fileName):
    searchWords = ('Type: Character', 'Type: Event', 'Type: Climax', 'Type: Unknown')
    with open(fileName, mode='r', encoding='utf-8') as f:
        pl = ''
        ppl = ''
        for line in f:
            pppl = ppl
            ppl = pl         
            pl = line
            if any(x in line for x in searchWords):
                return pppl

def getName(fileName):
    searchWords = ('Type: Character', 'Type: Event', 'Type: Climax', 'Type: Unknown')
    with open(fileName, mode='r', encoding='utf-8') as f:
        pl = ''
        ppl = ''
        pppl = ''
        for line in f:
            ppppl = pppl
            pppl = ppl
            ppl = pl         
            pl = line
            if any(x in line for x in searchWords):
                return ppppl

def getAB(fileName):
    with open(fileName, mode='r', encoding='utf-8') as f:
        temp = ''
        mode = 0
        for line in f:
            if 'Card Text/Abilities:' in line:
                mode = 1
            elif 'Flavor Text:' in line:
                mode = 2

            if mode == 1:
                temp = temp + line
            elif mode == 2:
                return temp 

def getFT(fileName):
    with open(fileName, mode='r', encoding='utf-8') as f:
        temp = ''
        mode = 0
        for line in f:
            if 'Flavor Text:' in line:
                mode = 1
            elif 'Copyright' in line:
                mode = 2

            if mode ==1:
                temp = temp + line
            elif mode ==2:
                return temp

def saveImage(fileName):
    with open(fileName, mode='r', encoding='utf-8') as f:
        for line in f:
            if 'large' in line:
                imLocation = line

    resource = urllib.request.Request(imLocation,headers={'User-Agent': 'Mozilla/5.0'})
    resource = urllib.request.urlopen(resource)
    with open(fileName[:-4] +'I.jpg',"wb") as f:
        f.write(resource.read())
    
#gets the sites 
def processMe(fileName, linkName, folder):
    #r = requests.get(str(linkName))
    #r.encoding="utf8"
    http = urllib3.PoolManager()
    r = http.request('GET', str(linkName))
    soup = BeautifulSoup(r.data,'html.parser')
    links = soup.find_all('a')
    with open(folder + '/' + str(fileName)+'.txt', mode ='w',encoding='utf-8') as f:
        f.write(soup.get_text())
        for each in links:
            f.write(each.get('href'))
            f.write('\n')
    getCard(fileName, folder, linkName)

def getCard(fileName, folder, link):
    fn = folder + '/' + str(fileName)+'.txt'
    with open(fn, mode ='r', encoding='utf-8') as f:
        data = f.read().encode("utf-8")

    #name = re.compile("<h4>.*</h4>", re.DOTALL).search(str(data)).group(0)
    #name = fixingText(name[4:-11])

    pwr = getPower(fn)
    soul = getSoul(fn)
    traits = getTrait(fn)
    trigger = getTrigger(fn)
    cost = getCost(fn)
    color = getColor(fn)
    level = getLevel(fn)
    types = getType(fn)
    code = getCode(fn)
    name = getName(fn)
    ab = getAB(fn)
    ft = getFT(fn)
    saveImage(fn)

    with open(folder + '/' + str(fileName)+'N.txt',mode='w',encoding='utf-8') as f:
        f.write(name)
        f.write(code)
        f.write(types)
        f.write(traits)
        f.write(level)
        f.write(color)
        f.write(cost)
        f.write(trigger)
        f.write(soul)
        f.write(pwr)
        f.write(ab)
        f.write(ft)
    
def startThisPage(url):
    #locating the side data
    r = requests.get(str(url))
    r.encoding="utf8"
    soup = BeautifulSoup(r.content,'html.parser')

    folderName = soup.h2.string.replace('/',' ').replace(':',' ')
    if folderName.endswith(' '):
        folderName = folderName[:-1]


    if not os.path.isdir(folderName):
        os.mkdir(folderName)

    listOfLinks = soup.find_all('a')
    counter = 0
    count = 0
    for item in listOfLinks:
        tempLink = item.get('href')
        if 'card.php?card_id' in tempLink:
            counter += 1
            t = threading.Thread(target=processMe,args=(counter,tempLink,folderName))
            t.start()
        
for each in range(1,119):
    startThisPage('http://littleakiba.com/tcg/weiss-schwarz/browse.php?series_id=5' + str(each))
    time.sleep(30
)
